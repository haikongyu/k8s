[INFO] [2020-11-20 02:31:49,574] [977:140399604672320] - task_executor.py[line:302]: report task 202011200231350021282_reader_0 0 host 9999 to driver
[INFO] [2020-11-20 02:31:49,579] [977:140399604672320] - control_client.py[line:42]: request update job 202011200231350021282 task 202011200231350021282_reader_0 0 on host 9999
[DEBUG] [2020-11-20 02:32:00,910] [977:140399604672320] - _federation.py[line:35]: [federation.eggroll]init federation: rp_session_id=202011200231350021282_reader_0_0_host_9999, rs_session_id=202011200231350021282_reader_0_0, party=Party(role=host, party_id=9999), proxy_endpoint=rollsite:9370
[DEBUG] [2020-11-20 02:32:00,913] [977:140399604672320] - _federation.py[line:45]: [federation.eggroll]init federation context done
[INFO] [2020-11-20 02:32:00,914] [977:140399604672320] - task_executor.py[line:156]: Run 202011200231350021282 reader_0 202011200231350021282_reader_0 host 9999 task
[INFO] [2020-11-20 02:32:00,915] [977:140399604672320] - task_executor.py[line:157]: Component parameters on party {'ReaderParam': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'dsl_version': '2', 'initiator': {'role': 'guest', 'party_id': 10000}, 'role': {'guest': [10000], 'host': [9999], 'arbiter': [9999]}, 'job_parameters': {'job_type': 'train', 'work_mode': 1, 'backend': 0, 'computing_engine': 'EGGROLL', 'federation_engine': 'EGGROLL', 'storage_engine': 'EGGROLL', 'engines_address': {'computing': {'cores_per_node': 20, 'nodes': 1}, 'federation': {'host': 'rollsite', 'port': 9370}, 'storage': {'cores_per_node': 20, 'nodes': 1}}, 'federated_mode': 'MULTIPLE', 'task_parallelism': 2, 'computing_partitions': 8, 'federated_status_collect_type': 'PUSH', 'model_id': 'arbiter-9999#guest-10000#host-9999#model', 'model_version': '202011200231350021282', 'eggroll_run': {'eggroll.session.processors.per.node': 2}, 'spark_run': {'num-executors': 1, 'executor-cores': 2}, 'rabbitmq_run': {}, 'adaptation_parameters': {'task_nodes': 1, 'task_cores_per_node': 2, 'task_memory_per_node': 0}}, 'component_parameters': {'common': {'intersect_0': {'intersect_method': 'raw', 'sync_intersect_ids': True, 'only_output_key': False}, 'hetero_lr_0': {'penalty': 'L2', 'optimizer': 'rmsprop', 'alpha': 0.01, 'max_iter': 3, 'batch_size': 320, 'learning_rate': 0.15, 'init_param': {'init_method': 'random_uniform'}}}, 'role': {'guest': {'0': {'reader_0': {'table': {'name': 'breast_hetero_guest', 'namespace': 'experiment'}}, 'dataio_0': {'with_label': True, 'label_name': 'y', 'label_type': 'int', 'output_format': 'dense'}}}, 'host': {'0': {'reader_0': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'dataio_0': {'with_label': False, 'output_format': 'dense'}}}}}, 'config': '/data/projects/fate/python/fate_flow/examples/test_hetero_lr_job_conf.json', 'dsl': 'examples/test_hetero_lr_job_dsl.json', 'function': 'submit_job', 'local': {'role': 'host', 'party_id': 9999}, 'CodePath': 'fate_flow/components/reader.py/Reader', 'module': 'Reader', 'output_data_name': ['table']}
[INFO] [2020-11-20 02:32:00,915] [977:140399604672320] - task_executor.py[line:158]: Task input dsl {}
[DEBUG] [2020-11-20 02:32:01,188] [977:140399604672320] - pool.py[line:129]: No connection available in pool.
[DEBUG] [2020-11-20 02:32:01,234] [977:140399604672320] - pool.py[line:158]: Created new connection 140399289012120.
[DEBUG] [2020-11-20 02:32:01,248] [977:140399604672320] - peewee.py[line:2863]: ('SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))', ['breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 02:32:01,277] [977:140399604672320] - pool.py[line:185]: Returning 140399289012120 to pool.
[DEBUG] [2020-11-20 02:32:01,311] [977:140399604672320] - peewee.py[line:2863]: ('INSERT INTO `t_session_record` (`f_session_id`, `f_create_date`, `f_update_time`, `f_update_date`, `f_engine_name`, `f_engine_type`, `f_engine_address`, `f_create_time`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)', ['202011200231350021282_reader_0_0_host_9999_storage_91d383682ad811eb8a243ea3df35c0a6', datetime.datetime(2020, 11, 20, 2, 32, 1), 1605839521290, datetime.datetime(2020, 11, 20, 2, 32, 1), 'EGGROLL', 'storage', '{}', 1605839521289])
[DEBUG] [2020-11-20 02:32:01,359] [977:140399604672320] - _session.py[line:144]: save session 202011200231350021282_reader_0_0_host_9999_storage_91d383682ad811eb8a243ea3df35c0a6 record
[DEBUG] [2020-11-20 02:32:01,361] [977:140399604672320] - pool.py[line:185]: Returning 140399289012120 to pool.
[DEBUG] [2020-11-20 02:32:07,802] [977:140399604672320] - peewee.py[line:2863]: ('SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))', ['breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 02:32:07,843] [977:140399604672320] - pool.py[line:185]: Returning 140399289012120 to pool.
[DEBUG] [2020-11-20 02:32:08,323] [977:140399604672320] - peewee.py[line:2863]: ('UPDATE `t_storage_table_meta` SET `f_count` = %s WHERE ((`t_storage_table_meta`.`f_name` = %s) AND (`t_storage_table_meta`.`f_namespace` = %s))', [569, 'breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 02:32:08,331] [977:140399604672320] - pool.py[line:185]: Returning 140399289012120 to pool.
[INFO] [2020-11-20 02:32:08,332] [977:140399604672320] - reader.py[line:84]: the EGGROLL engine input table does not require conversion to support computing engine EGGROLL
[DEBUG] [2020-11-20 02:32:10,242] [977:140399604672320] - peewee.py[line:2863]: ('DELETE FROM `t_session_record` WHERE (`t_session_record`.`f_session_id` = %s)', ['202011200231350021282_reader_0_0_host_9999_storage_91d383682ad811eb8a243ea3df35c0a6'])
[DEBUG] [2020-11-20 02:32:10,258] [977:140399604672320] - _session.py[line:153]: delete session 202011200231350021282_reader_0_0_host_9999_storage_91d383682ad811eb8a243ea3df35c0a6 record
[DEBUG] [2020-11-20 02:32:10,260] [977:140399604672320] - pool.py[line:185]: Returning 140399289012120 to pool.
[INFO] [2020-11-20 02:32:10,260] [977:140399604672320] - tracker_client.py[line:127]: Request save job 202011200231350021282 task 202011200231350021282_reader_0 0 on host 9999 data table info
[INFO] [2020-11-20 02:32:10,369] [977:140399604672320] - tracker_client.py[line:103]: Request save job 202011200231350021282 task 202011200231350021282_reader_0 0 on host 9999 metric reader_namespace reader_name meta
[INFO] [2020-11-20 02:32:10,505] [977:140399604672320] - profile.py[line:249]: 
Computing:
+----------+------------------------------------------+
| function |                                          |
+----------+------------------------------------------+
|  total   | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+----------+------------------------------------------+

Federation:
+--------+------------------------------------------+
|  get   |                                          |
+--------+------------------------------------------+
| remote |                                          |
+--------+------------------------------------------+
| total  | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+--------+------------------------------------------+

[DEBUG] [2020-11-20 02:32:10,508] [977:140399604672320] - profile.py[line:250]: 
Detailed Computing:
+-------+------------------------------------------+
| stack |                                          |
+-------+------------------------------------------+
| total | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+-------+------------------------------------------+

[INFO] [2020-11-20 02:32:10,511] [977:140399604672320] - task_executor.py[line:302]: report task 202011200231350021282_reader_0 0 host 9999 to driver
[INFO] [2020-11-20 02:32:10,512] [977:140399604672320] - control_client.py[line:42]: request update job 202011200231350021282 task 202011200231350021282_reader_0 0 on host 9999
[INFO] [2020-11-20 02:32:11,528] [977:140399604672320] - task_executor.py[line:207]: task 202011200231350021282_reader_0 host 9999 start time: 2020-11-20 02:31:49
[INFO] [2020-11-20 02:32:11,530] [977:140399604672320] - task_executor.py[line:209]: task 202011200231350021282_reader_0 host 9999 end time: 2020-11-20 02:32:10
[INFO] [2020-11-20 02:32:11,531] [977:140399604672320] - task_executor.py[line:211]: task 202011200231350021282_reader_0 host 9999 takes 21.382s
[INFO] [2020-11-20 02:32:11,533] [977:140399604672320] - task_executor.py[line:214]: Finish 202011200231350021282 reader_0 202011200231350021282_reader_0 0 host 9999 task success
[INFO] [2020-11-20 02:32:11,535] [977:140399604672320] - task_executor.py[line:302]: report task 202011200231350021282_reader_0 0 host 9999 to driver
[INFO] [2020-11-20 02:32:11,536] [977:140399604672320] - control_client.py[line:42]: request update job 202011200231350021282 task 202011200231350021282_reader_0 0 on host 9999
