[INFO] [2020-11-20 07:08:19,023] [19259:140634121942848] - task_executor.py[line:302]: report task 202011200707112994524_reader_0 0 host 9999 to driver
[INFO] [2020-11-20 07:08:19,025] [19259:140634121942848] - control_client.py[line:42]: request update job 202011200707112994524 task 202011200707112994524_reader_0 0 on host 9999
[DEBUG] [2020-11-20 07:08:31,965] [19259:140634121942848] - _federation.py[line:35]: [federation.eggroll]init federation: rp_session_id=202011200707112994524_reader_0_0_host_9999, rs_session_id=202011200707112994524_reader_0_0, party=Party(role=host, party_id=9999), proxy_endpoint=rollsite:9370
[DEBUG] [2020-11-20 07:08:31,968] [19259:140634121942848] - _federation.py[line:45]: [federation.eggroll]init federation context done
[INFO] [2020-11-20 07:08:31,969] [19259:140634121942848] - task_executor.py[line:156]: Run 202011200707112994524 reader_0 202011200707112994524_reader_0 host 9999 task
[INFO] [2020-11-20 07:08:31,970] [19259:140634121942848] - task_executor.py[line:157]: Component parameters on party {'ReaderParam': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'dsl_version': 2, 'initiator': {'role': 'guest', 'party_id': 10000}, 'role': {'host': [9999], 'guest': [10000]}, 'job_parameters': {'job_type': 'train', 'work_mode': 1, 'backend': 0, 'computing_engine': 'EGGROLL', 'federation_engine': 'EGGROLL', 'storage_engine': 'EGGROLL', 'engines_address': {'computing': {'cores_per_node': 20, 'nodes': 1}, 'federation': {'host': 'rollsite', 'port': 9370}, 'storage': {'cores_per_node': 20, 'nodes': 1}}, 'federated_mode': 'MULTIPLE', 'task_parallelism': 1, 'computing_partitions': 4, 'federated_status_collect_type': 'PUSH', 'model_id': 'guest-10000#host-9999#model', 'model_version': '202011200707112994524', 'eggroll_run': {'eggroll.session.processors.per.node': 4}, 'spark_run': {}, 'rabbitmq_run': {}, 'adaptation_parameters': {'task_nodes': 1, 'task_cores_per_node': 4, 'task_memory_per_node': 0}}, 'component_parameters': {'common': {'hetero_secure_boost_0': {'task_type': 'classification', 'objective_param': {'objective': 'cross_entropy'}, 'num_trees': 3, 'validation_freqs': 1, 'encrypt_param': {'method': 'iterativeAffine'}, 'tree_param': {'max_depth': 3}}, 'evaluation_0': {'eval_type': 'binary'}}, 'role': {'guest': {'0': {'reader_1': {'table': {'name': 'breast_hetero_guest', 'namespace': 'experiment'}}, 'reader_0': {'table': {'name': 'breast_hetero_guest', 'namespace': 'experiment'}}, 'dataio_0': {'with_label': True, 'output_format': 'dense'}, 'dataio_1': {'with_label': True, 'output_format': 'dense'}}}, 'host': {'0': {'reader_1': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'reader_0': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'dataio_0': {'with_label': False}, 'dataio_1': {'with_label': False}}}}}, 'config': '/data/projects/fate/python/fate_flow/examples/hetero_secureboost_conf.json', 'dsl': 'examples/hetero_secureboost_dsl.json', 'function': 'submit_job', 'local': {'role': 'host', 'party_id': 9999}, 'CodePath': 'fate_flow/components/reader.py/Reader', 'module': 'Reader', 'output_data_name': ['data']}
[INFO] [2020-11-20 07:08:31,972] [19259:140634121942848] - task_executor.py[line:158]: Task input dsl {}
[DEBUG] [2020-11-20 07:08:32,282] [19259:140634121942848] - pool.py[line:129]: No connection available in pool.
[DEBUG] [2020-11-20 07:08:32,358] [19259:140634121942848] - pool.py[line:158]: Created new connection 140633840332192.
[DEBUG] [2020-11-20 07:08:32,377] [19259:140634121942848] - peewee.py[line:2863]: ('SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))', ['breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 07:08:32,430] [19259:140634121942848] - pool.py[line:185]: Returning 140633840332192 to pool.
[DEBUG] [2020-11-20 07:08:32,469] [19259:140634121942848] - peewee.py[line:2863]: ('INSERT INTO `t_session_record` (`f_session_id`, `f_create_date`, `f_update_time`, `f_update_date`, `f_engine_name`, `f_engine_type`, `f_engine_address`, `f_create_time`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)', ['202011200707112994524_reader_0_0_host_9999_storage_32ecaace2aff11ebbbcf3ea3df35c0a6', datetime.datetime(2020, 11, 20, 7, 8, 32), 1605856112440, datetime.datetime(2020, 11, 20, 7, 8, 32), 'EGGROLL', 'storage', '{}', 1605856112440])
[DEBUG] [2020-11-20 07:08:32,514] [19259:140634121942848] - _session.py[line:144]: save session 202011200707112994524_reader_0_0_host_9999_storage_32ecaace2aff11ebbbcf3ea3df35c0a6 record
[DEBUG] [2020-11-20 07:08:32,515] [19259:140634121942848] - pool.py[line:185]: Returning 140633840332192 to pool.
[DEBUG] [2020-11-20 07:08:39,462] [19259:140634121942848] - peewee.py[line:2863]: ('SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))', ['breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 07:08:39,477] [19259:140634121942848] - pool.py[line:185]: Returning 140633840332192 to pool.
[DEBUG] [2020-11-20 07:08:39,982] [19259:140634121942848] - peewee.py[line:2863]: ('UPDATE `t_storage_table_meta` SET `f_count` = %s WHERE ((`t_storage_table_meta`.`f_name` = %s) AND (`t_storage_table_meta`.`f_namespace` = %s))', [569, 'breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 07:08:39,989] [19259:140634121942848] - pool.py[line:185]: Returning 140633840332192 to pool.
[INFO] [2020-11-20 07:08:39,991] [19259:140634121942848] - reader.py[line:84]: the EGGROLL engine input table does not require conversion to support computing engine EGGROLL
[DEBUG] [2020-11-20 07:08:41,581] [19259:140634121942848] - peewee.py[line:2863]: ('DELETE FROM `t_session_record` WHERE (`t_session_record`.`f_session_id` = %s)', ['202011200707112994524_reader_0_0_host_9999_storage_32ecaace2aff11ebbbcf3ea3df35c0a6'])
[DEBUG] [2020-11-20 07:08:41,599] [19259:140634121942848] - _session.py[line:153]: delete session 202011200707112994524_reader_0_0_host_9999_storage_32ecaace2aff11ebbbcf3ea3df35c0a6 record
[DEBUG] [2020-11-20 07:08:41,601] [19259:140634121942848] - pool.py[line:185]: Returning 140633840332192 to pool.
[INFO] [2020-11-20 07:08:41,603] [19259:140634121942848] - tracker_client.py[line:127]: Request save job 202011200707112994524 task 202011200707112994524_reader_0 0 on host 9999 data data info
[INFO] [2020-11-20 07:08:41,696] [19259:140634121942848] - tracker_client.py[line:103]: Request save job 202011200707112994524 task 202011200707112994524_reader_0 0 on host 9999 metric reader_namespace reader_name meta
[INFO] [2020-11-20 07:08:41,818] [19259:140634121942848] - profile.py[line:249]: 
Computing:
+----------+------------------------------------------+
| function |                                          |
+----------+------------------------------------------+
|  total   | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+----------+------------------------------------------+

Federation:
+--------+------------------------------------------+
|  get   |                                          |
+--------+------------------------------------------+
| remote |                                          |
+--------+------------------------------------------+
| total  | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+--------+------------------------------------------+

[DEBUG] [2020-11-20 07:08:41,822] [19259:140634121942848] - profile.py[line:250]: 
Detailed Computing:
+-------+------------------------------------------+
| stack |                                          |
+-------+------------------------------------------+
| total | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+-------+------------------------------------------+

[INFO] [2020-11-20 07:08:41,824] [19259:140634121942848] - task_executor.py[line:302]: report task 202011200707112994524_reader_0 0 host 9999 to driver
[INFO] [2020-11-20 07:08:41,825] [19259:140634121942848] - control_client.py[line:42]: request update job 202011200707112994524 task 202011200707112994524_reader_0 0 on host 9999
[INFO] [2020-11-20 07:08:43,101] [19259:140634121942848] - task_executor.py[line:207]: task 202011200707112994524_reader_0 host 9999 start time: 2020-11-20 07:08:18
[INFO] [2020-11-20 07:08:43,104] [19259:140634121942848] - task_executor.py[line:209]: task 202011200707112994524_reader_0 host 9999 end time: 2020-11-20 07:08:41
[INFO] [2020-11-20 07:08:43,106] [19259:140634121942848] - task_executor.py[line:211]: task 202011200707112994524_reader_0 host 9999 takes 23.285s
[INFO] [2020-11-20 07:08:43,107] [19259:140634121942848] - task_executor.py[line:214]: Finish 202011200707112994524 reader_0 202011200707112994524_reader_0 0 host 9999 task success
[INFO] [2020-11-20 07:08:43,109] [19259:140634121942848] - task_executor.py[line:302]: report task 202011200707112994524_reader_0 0 host 9999 to driver
[INFO] [2020-11-20 07:08:43,110] [19259:140634121942848] - control_client.py[line:42]: request update job 202011200707112994524 task 202011200707112994524_reader_0 0 on host 9999
