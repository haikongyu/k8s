[INFO] [2020-11-20 07:07:25,726] [18802:139627058091840] - task_executor.py[line:302]: report task 202011200707112994524_reader_1 0 host 9999 to driver
[INFO] [2020-11-20 07:07:25,730] [18802:139627058091840] - control_client.py[line:42]: request update job 202011200707112994524 task 202011200707112994524_reader_1 0 on host 9999
[DEBUG] [2020-11-20 07:07:38,881] [18802:139627058091840] - _federation.py[line:35]: [federation.eggroll]init federation: rp_session_id=202011200707112994524_reader_1_0_host_9999, rs_session_id=202011200707112994524_reader_1_0, party=Party(role=host, party_id=9999), proxy_endpoint=rollsite:9370
[DEBUG] [2020-11-20 07:07:38,885] [18802:139627058091840] - _federation.py[line:45]: [federation.eggroll]init federation context done
[INFO] [2020-11-20 07:07:38,886] [18802:139627058091840] - task_executor.py[line:156]: Run 202011200707112994524 reader_1 202011200707112994524_reader_1 host 9999 task
[INFO] [2020-11-20 07:07:38,887] [18802:139627058091840] - task_executor.py[line:157]: Component parameters on party {'ReaderParam': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'dsl_version': 2, 'initiator': {'role': 'guest', 'party_id': 10000}, 'role': {'host': [9999], 'guest': [10000]}, 'job_parameters': {'job_type': 'train', 'work_mode': 1, 'backend': 0, 'computing_engine': 'EGGROLL', 'federation_engine': 'EGGROLL', 'storage_engine': 'EGGROLL', 'engines_address': {'computing': {'cores_per_node': 20, 'nodes': 1}, 'federation': {'host': 'rollsite', 'port': 9370}, 'storage': {'cores_per_node': 20, 'nodes': 1}}, 'federated_mode': 'MULTIPLE', 'task_parallelism': 1, 'computing_partitions': 4, 'federated_status_collect_type': 'PUSH', 'model_id': 'guest-10000#host-9999#model', 'model_version': '202011200707112994524', 'eggroll_run': {'eggroll.session.processors.per.node': 4}, 'spark_run': {}, 'rabbitmq_run': {}, 'adaptation_parameters': {'task_nodes': 1, 'task_cores_per_node': 4, 'task_memory_per_node': 0}}, 'component_parameters': {'common': {'hetero_secure_boost_0': {'task_type': 'classification', 'objective_param': {'objective': 'cross_entropy'}, 'num_trees': 3, 'validation_freqs': 1, 'encrypt_param': {'method': 'iterativeAffine'}, 'tree_param': {'max_depth': 3}}, 'evaluation_0': {'eval_type': 'binary'}}, 'role': {'guest': {'0': {'reader_1': {'table': {'name': 'breast_hetero_guest', 'namespace': 'experiment'}}, 'reader_0': {'table': {'name': 'breast_hetero_guest', 'namespace': 'experiment'}}, 'dataio_0': {'with_label': True, 'output_format': 'dense'}, 'dataio_1': {'with_label': True, 'output_format': 'dense'}}}, 'host': {'0': {'reader_1': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'reader_0': {'table': {'name': 'breast_hetero_host', 'namespace': 'experiment'}}, 'dataio_0': {'with_label': False}, 'dataio_1': {'with_label': False}}}}}, 'config': '/data/projects/fate/python/fate_flow/examples/hetero_secureboost_conf.json', 'dsl': 'examples/hetero_secureboost_dsl.json', 'function': 'submit_job', 'local': {'role': 'host', 'party_id': 9999}, 'CodePath': 'fate_flow/components/reader.py/Reader', 'module': 'Reader', 'output_data_name': ['data']}
[INFO] [2020-11-20 07:07:38,889] [18802:139627058091840] - task_executor.py[line:158]: Task input dsl {}
[DEBUG] [2020-11-20 07:07:39,174] [18802:139627058091840] - pool.py[line:129]: No connection available in pool.
[DEBUG] [2020-11-20 07:07:39,219] [18802:139627058091840] - pool.py[line:158]: Created new connection 139626742398480.
[DEBUG] [2020-11-20 07:07:39,232] [18802:139627058091840] - peewee.py[line:2863]: ('SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))', ['breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 07:07:39,246] [18802:139627058091840] - pool.py[line:185]: Returning 139626742398480 to pool.
[DEBUG] [2020-11-20 07:07:39,280] [18802:139627058091840] - peewee.py[line:2863]: ('INSERT INTO `t_session_record` (`f_session_id`, `f_create_date`, `f_update_time`, `f_update_date`, `f_engine_name`, `f_engine_type`, `f_engine_address`, `f_create_time`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)', ['202011200707112994524_reader_1_0_host_9999_storage_133942282aff11eb97b63ea3df35c0a6', datetime.datetime(2020, 11, 20, 7, 7, 39), 1605856059255, datetime.datetime(2020, 11, 20, 7, 7, 39), 'EGGROLL', 'storage', '{}', 1605856059255])
[DEBUG] [2020-11-20 07:07:39,296] [18802:139627058091840] - _session.py[line:144]: save session 202011200707112994524_reader_1_0_host_9999_storage_133942282aff11eb97b63ea3df35c0a6 record
[DEBUG] [2020-11-20 07:07:39,297] [18802:139627058091840] - pool.py[line:185]: Returning 139626742398480 to pool.
[DEBUG] [2020-11-20 07:07:47,493] [18802:139627058091840] - peewee.py[line:2863]: ('SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))', ['breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 07:07:47,508] [18802:139627058091840] - pool.py[line:185]: Returning 139626742398480 to pool.
[DEBUG] [2020-11-20 07:07:47,908] [18802:139627058091840] - peewee.py[line:2863]: ('UPDATE `t_storage_table_meta` SET `f_count` = %s WHERE ((`t_storage_table_meta`.`f_name` = %s) AND (`t_storage_table_meta`.`f_namespace` = %s))', [569, 'breast_hetero_host', 'experiment'])
[DEBUG] [2020-11-20 07:07:47,915] [18802:139627058091840] - pool.py[line:185]: Returning 139626742398480 to pool.
[INFO] [2020-11-20 07:07:47,915] [18802:139627058091840] - reader.py[line:84]: the EGGROLL engine input table does not require conversion to support computing engine EGGROLL
[DEBUG] [2020-11-20 07:07:50,141] [18802:139627058091840] - peewee.py[line:2863]: ('DELETE FROM `t_session_record` WHERE (`t_session_record`.`f_session_id` = %s)', ['202011200707112994524_reader_1_0_host_9999_storage_133942282aff11eb97b63ea3df35c0a6'])
[DEBUG] [2020-11-20 07:07:50,159] [18802:139627058091840] - _session.py[line:153]: delete session 202011200707112994524_reader_1_0_host_9999_storage_133942282aff11eb97b63ea3df35c0a6 record
[DEBUG] [2020-11-20 07:07:50,160] [18802:139627058091840] - pool.py[line:185]: Returning 139626742398480 to pool.
[INFO] [2020-11-20 07:07:50,161] [18802:139627058091840] - tracker_client.py[line:127]: Request save job 202011200707112994524 task 202011200707112994524_reader_1 0 on host 9999 data data info
[INFO] [2020-11-20 07:07:50,269] [18802:139627058091840] - tracker_client.py[line:103]: Request save job 202011200707112994524 task 202011200707112994524_reader_1 0 on host 9999 metric reader_namespace reader_name meta
[INFO] [2020-11-20 07:07:50,452] [18802:139627058091840] - profile.py[line:249]: 
Computing:
+----------+------------------------------------------+
| function |                                          |
+----------+------------------------------------------+
|  total   | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+----------+------------------------------------------+

Federation:
+--------+------------------------------------------+
|  get   |                                          |
+--------+------------------------------------------+
| remote |                                          |
+--------+------------------------------------------+
| total  | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+--------+------------------------------------------+

[DEBUG] [2020-11-20 07:07:50,455] [18802:139627058091840] - profile.py[line:250]: 
Detailed Computing:
+-------+------------------------------------------+
| stack |                                          |
+-------+------------------------------------------+
| total | n=0, sum=0.0000, mean=0.0000, max=0.0000 |
+-------+------------------------------------------+

[INFO] [2020-11-20 07:07:50,457] [18802:139627058091840] - task_executor.py[line:302]: report task 202011200707112994524_reader_1 0 host 9999 to driver
[INFO] [2020-11-20 07:07:50,459] [18802:139627058091840] - control_client.py[line:42]: request update job 202011200707112994524 task 202011200707112994524_reader_1 0 on host 9999
[INFO] [2020-11-20 07:07:51,815] [18802:139627058091840] - task_executor.py[line:207]: task 202011200707112994524_reader_1 host 9999 start time: 2020-11-20 07:07:25
[INFO] [2020-11-20 07:07:51,816] [18802:139627058091840] - task_executor.py[line:209]: task 202011200707112994524_reader_1 host 9999 end time: 2020-11-20 07:07:50
[INFO] [2020-11-20 07:07:51,818] [18802:139627058091840] - task_executor.py[line:211]: task 202011200707112994524_reader_1 host 9999 takes 25.199s
[INFO] [2020-11-20 07:07:51,820] [18802:139627058091840] - task_executor.py[line:214]: Finish 202011200707112994524 reader_1 202011200707112994524_reader_1 0 host 9999 task success
[INFO] [2020-11-20 07:07:51,822] [18802:139627058091840] - task_executor.py[line:302]: report task 202011200707112994524_reader_1 0 host 9999 to driver
[INFO] [2020-11-20 07:07:51,823] [18802:139627058091840] - control_client.py[line:42]: request update job 202011200707112994524 task 202011200707112994524_reader_1 0 on host 9999
